NLP Disaster Tweets Model
Introduction
Welcome to my NLP Disaster Tweets model repository! In this project, I’ve built a model to predict whether a tweet is about a real disaster or not. 
The dataset used is from Kaggle’s “Natural Language Processing with Disaster Tweets” competition1.
Dataset Description
The dataset contains tweets, each labeled as either a disaster-related tweet (class 1) or a non-disaster tweet (class 0).
Our goal is to predict the correct class based on the tweet’s text.
Data Preprocessing
Cleaned and tokenized the tweet text.
Removed stop words and special characters.
Used techniques like stemming or lemmatization.
Exploratory Data Analysis (EDA)
Explored the distribution of disaster vs. non-disaster tweets.
Visualized word clouds to identify common terms in each class.
Feature Extraction
Used techniques like TF-IDF or word embeddings (e.g., Word2Vec, GloVe) to represent tweet text numerically.
Model Selection and Training
Explored various algorithms (e.g., logistic regression, random forests, neural networks).
Split data into training and validation sets.
Evaluated models using accuracy, precision, recall, and F1-score.
Model Performance
Our best model achieved an accuracy of 97% on the validation set.
Investigated misclassified tweets to understand model weaknesses.
Conclusion
This project demonstrates how natural language processing can classify disaster-related tweets. Feel free to explore the code and contribute!

Acknowledgments
Kaggle for providing the dataset.
References: Notebook 11, Notebook 22, Notebook 33, Notebook 44.
